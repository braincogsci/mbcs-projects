>[!caution] Policy changes
>UvA policy on the use of generative artificial intelligence is under development and therefore subject to change. Make sure you check current policies. 
>
>*This page was last updated on: 15-April-2025.*

### UvA policy
Current policy at the University of Amsterdam is a moratorium on the use of large language models (LLMs), such as ChatGPT, Gemini, Claude and others. See the following link for up-to-date information on the policy:

https://student.uva.nl/en/topics/ai-tools-and-your-studies

This means that the written work and any presentations for assessment in *Research Project 1*, *Research Project 2* and *Literature Thesis* may not be created with the help of LLMs. The UvA policy does allow students to use LLMs for e.g. summarising articles, organising notes, brainstorming ideas and other activities that support the research process, despite it being assessed.

### Ethical use
Please consider the following if using an LLM:

- [ ] Am I sharing sensitive information with third parties?
- [ ] Is my prompt/query worth the relatively high energy cost?
- [ ] Is the output from the LLM plausible?
- [ ] Can I verify whether the LLM output is accurate?
- [ ] Can I take ownership of the work for which I used the LLM?

### Teacher use
Quality assessment depends on the expertise of teachers and may therefore not be automated via LLMs. LLMs can be used, however, to formulate feedback on drafts.

As there are no reliable tools to detect the use of LLMs, teachers are asked to refrain from using them. Submission of the final work via the [[./Datanose project page|Datanose project page]] will automatically lead to a similarity-based plagiarism check.